{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6c96c017da3547d3bcb896fe5912ad5a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f17529dfdab47c1bf6e2c62a1b89c4a","IPY_MODEL_764c0aac19274228809c453f8e5c1f93","IPY_MODEL_a40b7deb39194be6af8e505515e78cc9"],"layout":"IPY_MODEL_54e08ff807834c6087dad6307fcc0eb6"}},"6f17529dfdab47c1bf6e2c62a1b89c4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a30576388f44b7cbba39d74bbb631c2","placeholder":"​","style":"IPY_MODEL_b621c07796d34872855525c0f99aa5d7","value":"Map: 100%"}},"764c0aac19274228809c453f8e5c1f93":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96d5df7ae1864642acc397fd41c11473","max":2478,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a70bb511275946869cd5a0b075dbac2f","value":2478}},"a40b7deb39194be6af8e505515e78cc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7e11708ed484e3cb1eca380c2c7310e","placeholder":"​","style":"IPY_MODEL_9e6a09c5c1a844b39cf14dbec5555e6d","value":" 2478/2478 [00:01&lt;00:00, 1588.93 examples/s]"}},"54e08ff807834c6087dad6307fcc0eb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a30576388f44b7cbba39d74bbb631c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b621c07796d34872855525c0f99aa5d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96d5df7ae1864642acc397fd41c11473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a70bb511275946869cd5a0b075dbac2f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7e11708ed484e3cb1eca380c2c7310e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e6a09c5c1a844b39cf14dbec5555e6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"63e81eb71d0d4887900de2ad3813b35c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_46f7d7ca64cf4055936f88141694b741","IPY_MODEL_1aafe36db33a4b2982a4b261dcc45acc","IPY_MODEL_d038fc22396440768885f237c0767bbb"],"layout":"IPY_MODEL_043b1a3a95d341b3845ca6686025108c"}},"46f7d7ca64cf4055936f88141694b741":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a66ac64b9b2a4fdd936fdcbb09cf9a8f","placeholder":"​","style":"IPY_MODEL_0c7ec0fd3b564998a5a163266472c6fd","value":"Map: 100%"}},"1aafe36db33a4b2982a4b261dcc45acc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4513fb496d5f4fd38605449c58d2bbc1","max":620,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eed0c1d6384f45d8ae2998be596ff36c","value":620}},"d038fc22396440768885f237c0767bbb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e8ec11fc4ad4e92b11a0e9a47456394","placeholder":"​","style":"IPY_MODEL_25a02c2875fd4a8cb265143d7e6d7c99","value":" 620/620 [00:00&lt;00:00, 1549.95 examples/s]"}},"043b1a3a95d341b3845ca6686025108c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a66ac64b9b2a4fdd936fdcbb09cf9a8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c7ec0fd3b564998a5a163266472c6fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4513fb496d5f4fd38605449c58d2bbc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed0c1d6384f45d8ae2998be596ff36c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e8ec11fc4ad4e92b11a0e9a47456394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25a02c2875fd4a8cb265143d7e6d7c99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2932913,"sourceType":"datasetVersion","datasetId":1798068}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"id":"Xp8RiF7NXtyB"}},{"cell_type":"code","source":"!pip install peft evaluate -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:22.012631Z","iopub.execute_input":"2024-10-21T19:55:22.012990Z","iopub.status.idle":"2024-10-21T19:55:36.112067Z","shell.execute_reply.started":"2024-10-21T19:55:22.012954Z","shell.execute_reply":"2024-10-21T19:55:36.110784Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset,  Dataset, DatasetDict\nfrom transformers import (\n    AutoTokenizer,\n    AutoConfig,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding)\n\nfrom sklearn.model_selection import train_test_split\n\nfrom peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\nimport evaluate\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\ntqdm.pandas()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnCQJT66tdsW","outputId":"84555d3e-fb5f-4232-da46-470d43b0a18c","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:36.114078Z","iopub.execute_input":"2024-10-21T19:55:36.114421Z","iopub.status.idle":"2024-10-21T19:55:56.732814Z","shell.execute_reply.started":"2024-10-21T19:55:36.114372Z","shell.execute_reply":"2024-10-21T19:55:56.731872Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Load dataset","metadata":{"id":"Orx0nzoQGsIa"}},{"cell_type":"code","source":"CSV_PATH = '/kaggle/input/supreme-court-judgment-prediction/justice.csv'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:56.734009Z","iopub.execute_input":"2024-10-21T19:55:56.734749Z","iopub.status.idle":"2024-10-21T19:55:56.742659Z","shell.execute_reply.started":"2024-10-21T19:55:56.734710Z","shell.execute_reply":"2024-10-21T19:55:56.739899Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def readFromCsv(filePath):\n    df = pd.read_csv(filePath)\n\n    # clean Unnamed col\n    df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n\n    # take a sneak peek\n    display(df.head())\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:56.745382Z","iopub.execute_input":"2024-10-21T19:55:56.745755Z","iopub.status.idle":"2024-10-21T19:55:56.786034Z","shell.execute_reply.started":"2024-10-21T19:55:56.745716Z","shell.execute_reply":"2024-10-21T19:55:56.785001Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"org_df = readFromCsv(CSV_PATH)\norg_df.info()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIGdmQKZHIeo","outputId":"ad1cae4c-c182-4abb-824b-99cc5fcc2e04","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:56.787419Z","iopub.execute_input":"2024-10-21T19:55:56.787819Z","iopub.status.idle":"2024-10-21T19:55:56.983283Z","shell.execute_reply.started":"2024-10-21T19:55:56.787775Z","shell.execute_reply":"2024-10-21T19:55:56.982185Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"      ID                     name                                     href  \\\n0  50606              Roe v. Wade    https://api.oyez.org/cases/1971/70-18   \n1  50613      Stanley v. Illinois  https://api.oyez.org/cases/1971/70-5014   \n2  50623  Giglio v. United States    https://api.oyez.org/cases/1971/70-29   \n3  50632             Reed v. Reed     https://api.oyez.org/cases/1971/70-4   \n4  50643     Miller v. California    https://api.oyez.org/cases/1971/70-73   \n\n    docket  term          first_party   second_party  \\\n0    70-18  1971             Jane Roe     Henry Wade   \n1  70-5014  1971  Peter Stanley, Sr.        Illinois   \n2    70-29  1971         John Giglio   United States   \n3     70-4  1971           Sally Reed     Cecil Reed   \n4    70-73  1971        Marvin Miller     California   \n\n                                               facts  facts_len  \\\n0  <p>In 1970, Jane Roe (a fictional name used in...        501   \n1  <p>Joan Stanley had three children with Peter ...        757   \n2  <p>John Giglio was convicted of passing forged...        495   \n3  <p>The Idaho Probate Code specified that \"male...        378   \n4  <p>Miller, after conducting a mass mailing cam...        305   \n\n   majority_vote  minority_vote first_party_winner     decision_type  \\\n0              7              2               True  majority opinion   \n1              5              2               True  majority opinion   \n2              7              0               True  majority opinion   \n3              7              0               True  majority opinion   \n4              5              4               True  majority opinion   \n\n         disposition       issue_area  \n0           reversed              NaN  \n1  reversed/remanded     Civil Rights  \n2  reversed/remanded      Due Process  \n3  reversed/remanded     Civil Rights  \n4   vacated/remanded  First Amendment  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>name</th>\n      <th>href</th>\n      <th>docket</th>\n      <th>term</th>\n      <th>first_party</th>\n      <th>second_party</th>\n      <th>facts</th>\n      <th>facts_len</th>\n      <th>majority_vote</th>\n      <th>minority_vote</th>\n      <th>first_party_winner</th>\n      <th>decision_type</th>\n      <th>disposition</th>\n      <th>issue_area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50606</td>\n      <td>Roe v. Wade</td>\n      <td>https://api.oyez.org/cases/1971/70-18</td>\n      <td>70-18</td>\n      <td>1971</td>\n      <td>Jane Roe</td>\n      <td>Henry Wade</td>\n      <td>&lt;p&gt;In 1970, Jane Roe (a fictional name used in...</td>\n      <td>501</td>\n      <td>7</td>\n      <td>2</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>reversed</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50613</td>\n      <td>Stanley v. Illinois</td>\n      <td>https://api.oyez.org/cases/1971/70-5014</td>\n      <td>70-5014</td>\n      <td>1971</td>\n      <td>Peter Stanley, Sr.</td>\n      <td>Illinois</td>\n      <td>&lt;p&gt;Joan Stanley had three children with Peter ...</td>\n      <td>757</td>\n      <td>5</td>\n      <td>2</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>reversed/remanded</td>\n      <td>Civil Rights</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50623</td>\n      <td>Giglio v. United States</td>\n      <td>https://api.oyez.org/cases/1971/70-29</td>\n      <td>70-29</td>\n      <td>1971</td>\n      <td>John Giglio</td>\n      <td>United States</td>\n      <td>&lt;p&gt;John Giglio was convicted of passing forged...</td>\n      <td>495</td>\n      <td>7</td>\n      <td>0</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>reversed/remanded</td>\n      <td>Due Process</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50632</td>\n      <td>Reed v. Reed</td>\n      <td>https://api.oyez.org/cases/1971/70-4</td>\n      <td>70-4</td>\n      <td>1971</td>\n      <td>Sally Reed</td>\n      <td>Cecil Reed</td>\n      <td>&lt;p&gt;The Idaho Probate Code specified that \"male...</td>\n      <td>378</td>\n      <td>7</td>\n      <td>0</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>reversed/remanded</td>\n      <td>Civil Rights</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50643</td>\n      <td>Miller v. California</td>\n      <td>https://api.oyez.org/cases/1971/70-73</td>\n      <td>70-73</td>\n      <td>1971</td>\n      <td>Marvin Miller</td>\n      <td>California</td>\n      <td>&lt;p&gt;Miller, after conducting a mass mailing cam...</td>\n      <td>305</td>\n      <td>5</td>\n      <td>4</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>vacated/remanded</td>\n      <td>First Amendment</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3303 entries, 0 to 3302\nData columns (total 15 columns):\n #   Column              Non-Null Count  Dtype \n---  ------              --------------  ----- \n 0   ID                  3303 non-null   int64 \n 1   name                3303 non-null   object\n 2   href                3303 non-null   object\n 3   docket              3292 non-null   object\n 4   term                3303 non-null   object\n 5   first_party         3302 non-null   object\n 6   second_party        3302 non-null   object\n 7   facts               3303 non-null   object\n 8   facts_len           3303 non-null   int64 \n 9   majority_vote       3303 non-null   int64 \n 10  minority_vote       3303 non-null   int64 \n 11  first_party_winner  3288 non-null   object\n 12  decision_type       3296 non-null   object\n 13  disposition         3231 non-null   object\n 14  issue_area          3161 non-null   object\ndtypes: int64(4), object(11)\nmemory usage: 387.2+ KB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Preprocess dataset","metadata":{"id":"YtPpS4jYTmgj"}},{"cell_type":"code","source":"# check for null before removing\norg_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:56.984853Z","iopub.execute_input":"2024-10-21T19:55:56.985268Z","iopub.status.idle":"2024-10-21T19:55:57.001099Z","shell.execute_reply.started":"2024-10-21T19:55:56.985220Z","shell.execute_reply":"2024-10-21T19:55:56.999816Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"ID                      0\nname                    0\nhref                    0\ndocket                 11\nterm                    0\nfirst_party             1\nsecond_party            1\nfacts                   0\nfacts_len               0\nmajority_vote           0\nminority_vote           0\nfirst_party_winner     15\ndecision_type           7\ndisposition            72\nissue_area            142\ndtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"org_df['augmented_text'] = \"\"\n\nfor idx, row in org_df.iterrows():\n    org_df.at[idx, 'augmented_text'] = f\"{row['name']} {row['first_party']} {row['second_party']} {row['majority_vote']} to {row['minority_vote']} {row['decision_type']} {row['disposition']}  {row['issue_area']} {row['facts']}\"\n\norg_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:57.002300Z","iopub.execute_input":"2024-10-21T19:55:57.002657Z","iopub.status.idle":"2024-10-21T19:55:57.441213Z","shell.execute_reply.started":"2024-10-21T19:55:57.002615Z","shell.execute_reply":"2024-10-21T19:55:57.440252Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      ID                     name                                     href  \\\n0  50606              Roe v. Wade    https://api.oyez.org/cases/1971/70-18   \n1  50613      Stanley v. Illinois  https://api.oyez.org/cases/1971/70-5014   \n2  50623  Giglio v. United States    https://api.oyez.org/cases/1971/70-29   \n3  50632             Reed v. Reed     https://api.oyez.org/cases/1971/70-4   \n4  50643     Miller v. California    https://api.oyez.org/cases/1971/70-73   \n\n    docket  term          first_party   second_party  \\\n0    70-18  1971             Jane Roe     Henry Wade   \n1  70-5014  1971  Peter Stanley, Sr.        Illinois   \n2    70-29  1971         John Giglio   United States   \n3     70-4  1971           Sally Reed     Cecil Reed   \n4    70-73  1971        Marvin Miller     California   \n\n                                               facts  facts_len  \\\n0  <p>In 1970, Jane Roe (a fictional name used in...        501   \n1  <p>Joan Stanley had three children with Peter ...        757   \n2  <p>John Giglio was convicted of passing forged...        495   \n3  <p>The Idaho Probate Code specified that \"male...        378   \n4  <p>Miller, after conducting a mass mailing cam...        305   \n\n   majority_vote  minority_vote first_party_winner     decision_type  \\\n0              7              2               True  majority opinion   \n1              5              2               True  majority opinion   \n2              7              0               True  majority opinion   \n3              7              0               True  majority opinion   \n4              5              4               True  majority opinion   \n\n         disposition       issue_area  \\\n0           reversed              NaN   \n1  reversed/remanded     Civil Rights   \n2  reversed/remanded      Due Process   \n3  reversed/remanded     Civil Rights   \n4   vacated/remanded  First Amendment   \n\n                                      augmented_text  \n0  Roe v. Wade Jane Roe Henry Wade 7 to 2 majorit...  \n1  Stanley v. Illinois Peter Stanley, Sr.  Illino...  \n2  Giglio v. United States John Giglio  United St...  \n3  Reed v. Reed Sally Reed Cecil Reed 7 to 0 majo...  \n4  Miller v. California Marvin Miller California ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>name</th>\n      <th>href</th>\n      <th>docket</th>\n      <th>term</th>\n      <th>first_party</th>\n      <th>second_party</th>\n      <th>facts</th>\n      <th>facts_len</th>\n      <th>majority_vote</th>\n      <th>minority_vote</th>\n      <th>first_party_winner</th>\n      <th>decision_type</th>\n      <th>disposition</th>\n      <th>issue_area</th>\n      <th>augmented_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>50606</td>\n      <td>Roe v. Wade</td>\n      <td>https://api.oyez.org/cases/1971/70-18</td>\n      <td>70-18</td>\n      <td>1971</td>\n      <td>Jane Roe</td>\n      <td>Henry Wade</td>\n      <td>&lt;p&gt;In 1970, Jane Roe (a fictional name used in...</td>\n      <td>501</td>\n      <td>7</td>\n      <td>2</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>reversed</td>\n      <td>NaN</td>\n      <td>Roe v. Wade Jane Roe Henry Wade 7 to 2 majorit...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50613</td>\n      <td>Stanley v. Illinois</td>\n      <td>https://api.oyez.org/cases/1971/70-5014</td>\n      <td>70-5014</td>\n      <td>1971</td>\n      <td>Peter Stanley, Sr.</td>\n      <td>Illinois</td>\n      <td>&lt;p&gt;Joan Stanley had three children with Peter ...</td>\n      <td>757</td>\n      <td>5</td>\n      <td>2</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>reversed/remanded</td>\n      <td>Civil Rights</td>\n      <td>Stanley v. Illinois Peter Stanley, Sr.  Illino...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>50623</td>\n      <td>Giglio v. United States</td>\n      <td>https://api.oyez.org/cases/1971/70-29</td>\n      <td>70-29</td>\n      <td>1971</td>\n      <td>John Giglio</td>\n      <td>United States</td>\n      <td>&lt;p&gt;John Giglio was convicted of passing forged...</td>\n      <td>495</td>\n      <td>7</td>\n      <td>0</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>reversed/remanded</td>\n      <td>Due Process</td>\n      <td>Giglio v. United States John Giglio  United St...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50632</td>\n      <td>Reed v. Reed</td>\n      <td>https://api.oyez.org/cases/1971/70-4</td>\n      <td>70-4</td>\n      <td>1971</td>\n      <td>Sally Reed</td>\n      <td>Cecil Reed</td>\n      <td>&lt;p&gt;The Idaho Probate Code specified that \"male...</td>\n      <td>378</td>\n      <td>7</td>\n      <td>0</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>reversed/remanded</td>\n      <td>Civil Rights</td>\n      <td>Reed v. Reed Sally Reed Cecil Reed 7 to 0 majo...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50643</td>\n      <td>Miller v. California</td>\n      <td>https://api.oyez.org/cases/1971/70-73</td>\n      <td>70-73</td>\n      <td>1971</td>\n      <td>Marvin Miller</td>\n      <td>California</td>\n      <td>&lt;p&gt;Miller, after conducting a mass mailing cam...</td>\n      <td>305</td>\n      <td>5</td>\n      <td>4</td>\n      <td>True</td>\n      <td>majority opinion</td>\n      <td>vacated/remanded</td>\n      <td>First Amendment</td>\n      <td>Miller v. California Marvin Miller California ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# as we are primarily concerned about whether first party won or lost,\n# discard only those nan rows for the moment\n\ndef removeNaN(df, colName):\n    df = df.copy()\n    df = df.dropna(subset=[colName])\n    return df\n    \ncleaned_df = removeNaN(org_df, 'first_party_winner')\ncleaned_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:57.442586Z","iopub.execute_input":"2024-10-21T19:55:57.443314Z","iopub.status.idle":"2024-10-21T19:55:57.463642Z","shell.execute_reply.started":"2024-10-21T19:55:57.443268Z","shell.execute_reply":"2024-10-21T19:55:57.462684Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"ID                      0\nname                    0\nhref                    0\ndocket                 10\nterm                    0\nfirst_party             1\nsecond_party            1\nfacts                   0\nfacts_len               0\nmajority_vote           0\nminority_vote           0\nfirst_party_winner      0\ndecision_type           6\ndisposition            65\nissue_area            129\naugmented_text          0\ndtype: int64"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# get features and target\ndef getFeatureNTarget(df):\n    df = df.copy()\n    df = df[['augmented_text', 'first_party_winner']]\n    df['first_party_winner'] = df['first_party_winner'].astype(int)\n    \n    #rename facts to text and first_party_winner to label\n    df = df.rename(columns={'first_party_winner': 'labels', 'augmented_text': 'text'})\n\n    return df.reset_index(drop=True)\n\ntrain_df = getFeatureNTarget(cleaned_df)\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:57.464727Z","iopub.execute_input":"2024-10-21T19:55:57.465050Z","iopub.status.idle":"2024-10-21T19:55:57.481855Z","shell.execute_reply.started":"2024-10-21T19:55:57.465016Z","shell.execute_reply":"2024-10-21T19:55:57.480742Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                   text  labels\n0     Roe v. Wade Jane Roe Henry Wade 7 to 2 majorit...       1\n1     Stanley v. Illinois Peter Stanley, Sr.  Illino...       1\n2     Giglio v. United States John Giglio  United St...       1\n3     Reed v. Reed Sally Reed Cecil Reed 7 to 0 majo...       1\n4     Miller v. California Marvin Miller California ...       1\n...                                                 ...     ...\n3283  United States v. Palomar-Santiago United State...       1\n3284  Terry v. United States Tarahrick Terry United ...       0\n3285  United States v. Cooley United States Joshua J...       1\n3286  Florida v. Georgia Florida Georgia 9 to 0 majo...       0\n3287  PennEast Pipeline Co. v. New Jersey PennEast P...       1\n\n[3288 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Roe v. Wade Jane Roe Henry Wade 7 to 2 majorit...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Stanley v. Illinois Peter Stanley, Sr.  Illino...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Giglio v. United States John Giglio  United St...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Reed v. Reed Sally Reed Cecil Reed 7 to 0 majo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Miller v. California Marvin Miller California ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3283</th>\n      <td>United States v. Palomar-Santiago United State...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3284</th>\n      <td>Terry v. United States Tarahrick Terry United ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3285</th>\n      <td>United States v. Cooley United States Joshua J...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3286</th>\n      <td>Florida v. Georgia Florida Georgia 9 to 0 majo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3287</th>\n      <td>PennEast Pipeline Co. v. New Jersey PennEast P...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3288 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# now we have the base version of our train dataset with basic feature and it's target\n# here on, we will apply preprocessing if and where required\ndef preprocess_text(text):\n    # remove <p> tag\n    text = text.replace('<p>', '')\n    return text\n\n# apply preprocess on train_df\ndef apply_preprocess(df, colName):\n    df = df.copy() # reason why I'm doing a copy with each utility function is that I don't wanna alter original data frame\n    df[colName] = df[colName].progress_apply(preprocess_text)\n    return df\n\nprocessed_df = apply_preprocess(train_df, 'text')\nprocessed_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:57.486479Z","iopub.execute_input":"2024-10-21T19:55:57.486861Z","iopub.status.idle":"2024-10-21T19:55:57.518598Z","shell.execute_reply.started":"2024-10-21T19:55:57.486797Z","shell.execute_reply":"2024-10-21T19:55:57.517733Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 3288/3288 [00:00<00:00, 263733.18it/s]\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                   text  labels\n0     Roe v. Wade Jane Roe Henry Wade 7 to 2 majorit...       1\n1     Stanley v. Illinois Peter Stanley, Sr.  Illino...       1\n2     Giglio v. United States John Giglio  United St...       1\n3     Reed v. Reed Sally Reed Cecil Reed 7 to 0 majo...       1\n4     Miller v. California Marvin Miller California ...       1\n...                                                 ...     ...\n3283  United States v. Palomar-Santiago United State...       1\n3284  Terry v. United States Tarahrick Terry United ...       0\n3285  United States v. Cooley United States Joshua J...       1\n3286  Florida v. Georgia Florida Georgia 9 to 0 majo...       0\n3287  PennEast Pipeline Co. v. New Jersey PennEast P...       1\n\n[3288 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Roe v. Wade Jane Roe Henry Wade 7 to 2 majorit...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Stanley v. Illinois Peter Stanley, Sr.  Illino...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Giglio v. United States John Giglio  United St...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Reed v. Reed Sally Reed Cecil Reed 7 to 0 majo...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Miller v. California Marvin Miller California ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3283</th>\n      <td>United States v. Palomar-Santiago United State...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3284</th>\n      <td>Terry v. United States Tarahrick Terry United ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3285</th>\n      <td>United States v. Cooley United States Joshua J...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3286</th>\n      <td>Florida v. Georgia Florida Georgia 9 to 0 majo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3287</th>\n      <td>PennEast Pipeline Co. v. New Jersey PennEast P...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3288 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Validation Split","metadata":{"id":"A3lO70H0qCBH"}},{"cell_type":"code","source":"# Split the dataset into training and testing sets\ndf_train, df_test = train_test_split(processed_df, test_size=0.2, random_state=42)\n\n# Convert the dataframes to Hugging Face Datasets\ntrain_dataset = Dataset.from_pandas(df_train)\nvalidation_dataset = Dataset.from_pandas(df_test)\n\n# pick only feature and target column\ntrain_dataset = train_dataset.select_columns(['text', 'labels'])\nvalidation_dataset = validation_dataset.select_columns(['text', 'labels'])\n\ndataset = DatasetDict({\n    'train': train_dataset,\n    'validation': validation_dataset\n})\n\ndataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QpcFeq58uOQS","outputId":"49cb13d2-2d97-4370-f45e-f7313833c871","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:57.519673Z","iopub.execute_input":"2024-10-21T19:55:57.519984Z","iopub.status.idle":"2024-10-21T19:55:57.594167Z","shell.execute_reply.started":"2024-10-21T19:55:57.519951Z","shell.execute_reply":"2024-10-21T19:55:57.593273Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'labels'],\n        num_rows: 2630\n    })\n    validation: Dataset({\n        features: ['text', 'labels'],\n        num_rows: 658\n    })\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# Classfical Approach: Tf-Idf","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:57.595307Z","iopub.execute_input":"2024-10-21T19:55:57.595698Z","iopub.status.idle":"2024-10-21T19:55:57.947778Z","shell.execute_reply.started":"2024-10-21T19:55:57.595643Z","shell.execute_reply":"2024-10-21T19:55:57.946954Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"X_train = df_train['text'].str.lower().values\ny_train = df_train['labels']\nX_test = df_test['text'].str.lower().values\ny_test = df_test['labels']\n\ntfidf_vectorizer = TfidfVectorizer()\nX_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\nX_test_tfidf = tfidf_vectorizer.transform(X_test)\n\n# Train the classifier\nclassifier = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\nclassifier.fit(X_train_tfidf, y_train)\n\n# Make predictions and evaluate\ny_pred = classifier.predict(X_test_tfidf)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy:.2f}')\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:55:57.948932Z","iopub.execute_input":"2024-10-21T19:55:57.949247Z","iopub.status.idle":"2024-10-21T19:56:04.951319Z","shell.execute_reply.started":"2024-10-21T19:55:57.949214Z","shell.execute_reply":"2024-10-21T19:56:04.950222Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.88\n              precision    recall  f1-score   support\n\n           0       0.94      0.73      0.83       252\n           1       0.85      0.97      0.91       406\n\n    accuracy                           0.88       658\n   macro avg       0.90      0.85      0.87       658\nweighted avg       0.89      0.88      0.88       658\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Tokenize","metadata":{"id":"ZSsLAj4lqR09"}},{"cell_type":"code","source":"model_name = \"microsoft/deberta-v3-small\" # using this base model for doing binary classfication because it is the smallest parameter set, can run in this machine.\n\n# we want to fine-tune this model to do case analysis on input text, for that we want to label map for First party wins and First party losses.\n# define label maps\nid2label = {0: \"First Party Loses\", 1: \"First Party Wins\"}\nlabel2id = {\"First Party Loses\": 0, \"First Party Wins\": 1}\n\n#generate classification model for model_checkpoint\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=2,\n    # id2label=id2label,\n    # label2id=label2id\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:56:04.952434Z","iopub.execute_input":"2024-10-21T19:56:04.952742Z","iopub.status.idle":"2024-10-21T19:56:07.554925Z","shell.execute_reply.started":"2024-10-21T19:56:04.952708Z","shell.execute_reply":"2024-10-21T19:56:07.553971Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ef095aa24d34321832a6759d25e4c59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/286M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51c858631c164246a39d73d4cea02dfe"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Load tokenizer from pretrained model\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Function to tokenize dataset rows\ndef tokenize_function(examples):\n    text = examples['text']  # Extract the text from the dataset\n\n    # Tokenize and truncate, with max_length set to 512 and truncation from the left\n    tokenized_inputs = tokenizer(text, \n                                 return_tensors=\"np\", \n                                 max_length=512, \n                                 truncation=True,\n                                padding='max_length')\n\n    # Add a padding token if it's missing\n    # if tokenizer.pad_token is None:\n    #     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    #     model.resize_token_embeddings(len(tokenizer))  # Resize embeddings for model (requires model object)\n\n    return tokenized_inputs\n\n# Tokenize the dataset, assuming it's in a format compatible with the .map() method\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n# Use a collator to dynamically pad sequences during batching\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# Output the tokenized dataset\ntokenized_dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["6c96c017da3547d3bcb896fe5912ad5a","6f17529dfdab47c1bf6e2c62a1b89c4a","764c0aac19274228809c453f8e5c1f93","a40b7deb39194be6af8e505515e78cc9","54e08ff807834c6087dad6307fcc0eb6","8a30576388f44b7cbba39d74bbb631c2","b621c07796d34872855525c0f99aa5d7","96d5df7ae1864642acc397fd41c11473","a70bb511275946869cd5a0b075dbac2f","b7e11708ed484e3cb1eca380c2c7310e","9e6a09c5c1a844b39cf14dbec5555e6d","63e81eb71d0d4887900de2ad3813b35c","46f7d7ca64cf4055936f88141694b741","1aafe36db33a4b2982a4b261dcc45acc","d038fc22396440768885f237c0767bbb","043b1a3a95d341b3845ca6686025108c","a66ac64b9b2a4fdd936fdcbb09cf9a8f","0c7ec0fd3b564998a5a163266472c6fd","4513fb496d5f4fd38605449c58d2bbc1","eed0c1d6384f45d8ae2998be596ff36c","3e8ec11fc4ad4e92b11a0e9a47456394","25a02c2875fd4a8cb265143d7e6d7c99"]},"id":"6_e_1Gpnwxlq","outputId":"30e93751-5ebc-4d8c-afba-0f74db9680fc","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:56:07.556202Z","iopub.execute_input":"2024-10-21T19:56:07.556524Z","iopub.status.idle":"2024-10-21T19:56:11.043385Z","shell.execute_reply.started":"2024-10-21T19:56:07.556491Z","shell.execute_reply":"2024-10-21T19:56:11.042300Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b709f194de114dd9a1766842a7e219ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1889f95dcfc4227ba74f51b958a6b40"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:558: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2630 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6e12d476545492faba739bc1ec8f640"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/658 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f21a47e5070493eb8ab99c764d85226"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2630\n    })\n    validation: Dataset({\n        features: ['text', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 658\n    })\n})"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"# Evaluation metrics","metadata":{"id":"y-TZYxV7qWrT"}},{"cell_type":"code","source":"# to import the performance of the model during training\n# import accuracy evaluation metrics\naccuracy = evaluate.load(\"accuracy\")\n\n# packaging accuracy metrics as a function, one for first party losses and first party losses class, whichever is larger will become model prediction.\n# define an evaluation function to pass into trainer later\ndef compute_metrics(eval_pred):\n  predictions, labels = eval_pred # predictions here are the logits, has 2 elements + and -, evaluating which element is larger and which is larger will be the label.\n  predictions = np.argmax(predictions, axis=1)\n  return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}","metadata":{"id":"02088sTPyN6V","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:56:11.044703Z","iopub.execute_input":"2024-10-21T19:56:11.045030Z","iopub.status.idle":"2024-10-21T19:56:11.470662Z","shell.execute_reply.started":"2024-10-21T19:56:11.044996Z","shell.execute_reply":"2024-10-21T19:56:11.469869Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bea230dadd74fbb87e67e087ac75f57"}},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"# Zero-shot Inference","metadata":{"id":"9-ihK7WRquQr"}},{"cell_type":"code","source":"# define list of examples\ntext_list = df_test['text'][5:10].tolist()\nactual_winner = df_test['labels'][5:10].tolist()\nprint(\"Untrained model predictions:\")\nprint(\"----------------------------\")\n\nfor text in text_list:\n    # tokenize text\n    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n    # compute logits\n    logits = model(inputs).logits\n    # convert logits to label\n    predictions = torch.argmax(logits)\n    print(id2label[predictions.tolist()]\n          + \" - Actual Result: \" + id2label[actual_winner[text_list.index(text)]])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4pAGB9DyWld","outputId":"788f1c46-d5d6-4154-ac25-b6aeccf2b438","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:56:11.472114Z","iopub.execute_input":"2024-10-21T19:56:11.472885Z","iopub.status.idle":"2024-10-21T19:56:13.028089Z","shell.execute_reply.started":"2024-10-21T19:56:11.472816Z","shell.execute_reply":"2024-10-21T19:56:13.027141Z"}},"outputs":[{"name":"stdout","text":"Untrained model predictions:\n----------------------------\nFirst Party Wins - Actual Result: First Party Loses\nFirst Party Wins - Actual Result: First Party Wins\nFirst Party Wins - Actual Result: First Party Wins\nFirst Party Wins - Actual Result: First Party Wins\nFirst Party Wins - Actual Result: First Party Loses\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Fine-tune","metadata":{"id":"hX5jKhNMq2Qu"}},{"cell_type":"code","source":"peft_config = LoraConfig(\n    task_type=\"SEQ_CLS\", # sequence classification\n    inference_mode=False,\n    r=4, #intrinsic rank of trainable weight matrix\n    lora_alpha=32, # learning rate\n    lora_dropout=0.01, # probability of drop out, randomly 0 internal parameters during training\n    target_modules = [\"query_proj\"] #, \"value_proj\"] # to see which modules to target, just print the layers\n)  # apply lora to query layer","metadata":{"id":"ZFK93dcJzQpN","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:56:13.029689Z","iopub.execute_input":"2024-10-21T19:56:13.030414Z","iopub.status.idle":"2024-10-21T19:56:13.034924Z","shell.execute_reply.started":"2024-10-21T19:56:13.030373Z","shell.execute_reply":"2024-10-21T19:56:13.034033Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"model = get_peft_model(model, peft_config) # get actual model and update it using the configuration of lora that we provided in previous step\nmodel.print_trainable_parameters() # to see how much percentage of total parameters we actually need to model, as seen in result only 0.93% of the model will be trained, huge cost savings.","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SlvHbpLxzz7P","outputId":"17045563-426a-41e3-f988-d3a7235193d2","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:56:13.036113Z","iopub.execute_input":"2024-10-21T19:56:13.036647Z","iopub.status.idle":"2024-10-21T19:56:13.060283Z","shell.execute_reply.started":"2024-10-21T19:56:13.036614Z","shell.execute_reply":"2024-10-21T19:56:13.059446Z"}},"outputs":[{"name":"stdout","text":"trainable params: 38,402 || all params: 141,934,852 || trainable%: 0.0271\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# hyperparameters\nlr = 1e-3 # size of optimization step\nbatch_size = 4 # number of rows in dataset processed per optimization step\nnum_epochs = 10 #number of times model runs through training data","metadata":{"id":"QoelnMZxz4HP","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:56:13.061361Z","iopub.execute_input":"2024-10-21T19:56:13.061681Z","iopub.status.idle":"2024-10-21T19:56:13.065872Z","shell.execute_reply.started":"2024-10-21T19:56:13.061646Z","shell.execute_reply":"2024-10-21T19:56:13.064961Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# define training arguments\ntraining_args = TrainingArguments(\n    output_dir= f'./{model_name}-lora-text-classification', # defining where model to be saved\n    learning_rate=lr,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    weight_decay=0.01,\n    eval_strategy=\"epoch\", # per epoch evaluate the model parameters\n    save_strategy=\"epoch\", # per epoch save the model parameters\n    load_best_model_at_end=True, # at end return best version of the model\n)","metadata":{"id":"UjrDQbwlz81y","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:56:13.067122Z","iopub.execute_input":"2024-10-21T19:56:13.067459Z","iopub.status.idle":"2024-10-21T19:56:13.139712Z","shell.execute_reply.started":"2024-10-21T19:56:13.067425Z","shell.execute_reply":"2024-10-21T19:56:13.138885Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Create a Trainer object\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n# Train the model\ntrainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"id":"lHcqrL1p277-","outputId":"3940f658-3277-47a3-9796-1d881db8a76d","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T19:56:13.140910Z","iopub.execute_input":"2024-10-21T19:56:13.141303Z","iopub.status.idle":"2024-10-21T20:17:28.911657Z","shell.execute_reply.started":"2024-10-21T19:56:13.141241Z","shell.execute_reply":"2024-10-21T20:17:28.910717Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112873600000562, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f5ad0a1fcd940f594dd29797dedc69f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241021_195619-f5dier4t</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ultron01/huggingface/runs/f5dier4t' target=\"_blank\">./microsoft/deberta-v3-small-lora-text-classification</a></strong> to <a href='https://wandb.ai/ultron01/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ultron01/huggingface' target=\"_blank\">https://wandb.ai/ultron01/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ultron01/huggingface/runs/f5dier4t' target=\"_blank\">https://wandb.ai/ultron01/huggingface/runs/f5dier4t</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3290' max='3290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3290/3290 21:04, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.231626</td>\n      <td>{'accuracy': 0.9559270516717325}</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.284900</td>\n      <td>0.239165</td>\n      <td>{'accuracy': 0.958966565349544}</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.284900</td>\n      <td>0.194412</td>\n      <td>{'accuracy': 0.9620060790273556}</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.170600</td>\n      <td>0.200408</td>\n      <td>{'accuracy': 0.958966565349544}</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.159800</td>\n      <td>0.186323</td>\n      <td>{'accuracy': 0.9620060790273556}</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.159800</td>\n      <td>0.200447</td>\n      <td>{'accuracy': 0.9620060790273556}</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.137900</td>\n      <td>0.220921</td>\n      <td>{'accuracy': 0.9604863221884499}</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.127400</td>\n      <td>0.213209</td>\n      <td>{'accuracy': 0.9604863221884499}</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.127400</td>\n      <td>0.210113</td>\n      <td>{'accuracy': 0.9650455927051672}</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.117200</td>\n      <td>0.214385</td>\n      <td>{'accuracy': 0.9620060790273556}</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"{'accuracy': 0.9559270516717325}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"{'accuracy': 0.958966565349544}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"{'accuracy': 0.9620060790273556}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"{'accuracy': 0.958966565349544}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"{'accuracy': 0.9620060790273556}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"{'accuracy': 0.9620060790273556}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"{'accuracy': 0.9604863221884499}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"{'accuracy': 0.9604863221884499}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"{'accuracy': 0.9650455927051672}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nTrainer is attempting to log a value of \"{'accuracy': 0.9620060790273556}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3290, training_loss=0.1623167484364611, metrics={'train_runtime': 1274.0732, 'train_samples_per_second': 20.642, 'train_steps_per_second': 2.582, 'total_flos': 3487119319449600.0, 'train_loss': 0.1623167484364611, 'epoch': 10.0})"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# evaluate\ntrainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-21T20:17:47.241782Z","iopub.execute_input":"2024-10-21T20:17:47.242178Z","iopub.status.idle":"2024-10-21T20:18:00.699802Z","shell.execute_reply.started":"2024-10-21T20:17:47.242140Z","shell.execute_reply":"2024-10-21T20:18:00.698845Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='83' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [83/83 00:13]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Trainer is attempting to log a value of \"{'accuracy': 0.9620060790273556}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.18632306158542633,\n 'eval_accuracy': {'accuracy': 0.9620060790273556},\n 'eval_runtime': 13.4433,\n 'eval_samples_per_second': 48.946,\n 'eval_steps_per_second': 6.174,\n 'epoch': 10.0}"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"# define list of examples\ntext_list = df_test['text'][5:10].tolist()\nactual_winner = df_test['labels'][5:10].tolist()\n\nprint(\"Trained model predictions:\")\nprint(\"----------------------------\")\n\nfor text in text_list:\n    # tokenize text\n    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"cuda\")\n    # compute logits\n    logits = model(inputs).logits\n    # convert logits to label\n    predictions = torch.argmax(logits)\n    print(id2label[predictions.tolist()]\n          + \" - Actual Result: \" + id2label[actual_winner[text_list.index(text)]])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9x--MdVsfux","outputId":"ffaeb1de-b198-4cf9-8421-f461fee1b876","trusted":true,"execution":{"iopub.status.busy":"2024-10-21T20:17:40.543928Z","iopub.execute_input":"2024-10-21T20:17:40.544315Z","iopub.status.idle":"2024-10-21T20:17:40.724326Z","shell.execute_reply.started":"2024-10-21T20:17:40.544276Z","shell.execute_reply":"2024-10-21T20:17:40.723235Z"}},"outputs":[{"name":"stdout","text":"Trained model predictions:\n----------------------------\nFirst Party Loses - Actual Result: First Party Loses\nFirst Party Wins - Actual Result: First Party Wins\nFirst Party Wins - Actual Result: First Party Wins\nFirst Party Wins - Actual Result: First Party Wins\nFirst Party Loses - Actual Result: First Party Loses\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# End","metadata":{}}]}